"use strict";(self.webpackChunkreact_native_gesture_handler_docs=self.webpackChunkreact_native_gesture_handler_docs||[]).push([[499],{3905:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return m}});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=r.createContext({}),l=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=l(e.components);return r.createElement(c.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),d=l(n),m=o,g=d["".concat(c,".").concat(m)]||d[m]||p[m]||a;return n?r.createElement(g,i(i({ref:t},u),{},{components:n})):r.createElement(g,i({ref:t},u))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,i=new Array(a);i[0]=d;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var l=2;l<a;l++)i[l]=n[l];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},6645:function(e,t,n){n.r(t),n.d(t,{assets:function(){return u},contentTitle:function(){return c},default:function(){return m},frontMatter:function(){return s},metadata:function(){return l},toc:function(){return p}});var r=n(3117),o=(n(7294),n(3905));const a={toc:[]};function i(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,r.Z)({},a,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-jsx"},"export default function Example() {\n  const tap = Gesture.Tap().onStart(() => {\n    console.log('tap');\n  });\n\n  return (\n    <GestureDetector gesture={tap}>\n      <FunctionalComponent>\n        <View style={styles.box} />\n      </FunctionalComponent>\n    </GestureDetector>\n  );\n}\n\nfunction FunctionalComponent(props) {\n  return <View collapsable={false}>{props.children}</View>;\n}\n")))}i.isMDXComponent=!0;const s={id:"gesture-detector",title:"GestureDetector",sidebar_label:"Gesture detector",sidebar_position:1},c=void 0,l={unversionedId:"gestures/gesture-detector",id:"gestures/gesture-detector",title:"GestureDetector",description:"GestureDetector is the main component of the RNGH2. It is responsible for creating and updating native gesture handlers based on the config of provided gesture. The most significant difference between it and old gesture handlers is that the GestureDetector can recognize more than one gesture at the time thanks to gesture composition. Keep in mind that GestureDetector is not compatible with the Animated API, nor with Reanimated 1.",source:"@site/docs/gestures/gesture-detector.md",sourceDirName:"gestures",slug:"/gestures/gesture-detector",permalink:"/react-native-gesture-handler/docs/gestures/gesture-detector",draft:!1,editUrl:"https://github.com/software-mansion/react-native-gesture-handler/edit/main/docs/docs/gestures/gesture-detector.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"gesture-detector",title:"GestureDetector",sidebar_label:"Gesture detector",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Gestures",permalink:"/react-native-gesture-handler/docs/category/gestures"},next:{title:"Gesture",permalink:"/react-native-gesture-handler/docs/gestures/gesture"}},u={},p=[{value:"Reference",id:"reference",level:2},{value:"Properties",id:"properties",level:2},{value:"<code>gesture</code>",id:"gesture",level:3},{value:"<code>userSelect</code> (<strong>web only</strong>)",id:"userselect-web-only",level:3},{value:"Remarks",id:"remarks",level:2}],d={toc:p};function m(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,r.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"GestureDetector")," is the main component of the RNGH2. It is responsible for creating and updating native gesture handlers based on the config of provided gesture. The most significant difference between it and old gesture handlers is that the ",(0,o.kt)("inlineCode",{parentName:"p"},"GestureDetector")," can recognize more than one gesture at the time thanks to gesture composition. Keep in mind that ",(0,o.kt)("inlineCode",{parentName:"p"},"GestureDetector")," is not compatible with the ",(0,o.kt)("a",{parentName:"p",href:"https://reactnative.dev/docs/animated"},"Animated API"),", nor with ",(0,o.kt)("a",{parentName:"p",href:"https://docs.swmansion.com/react-native-reanimated/docs/1.x/"},"Reanimated 1"),"."),(0,o.kt)("h2",{id:"reference"},"Reference"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-javascript"},"import { GestureDetector } from 'react-native-gesture-handler';\n\nfunction App() {\n  const tap = Gesture.Tap();\n  return (\n    // highlight-next-line\n    <GestureDetector gesture={tap}>\n      <Animated.View />\n      // highlight-next-line\n    </GestureDetector>\n  );\n}\n")),(0,o.kt)("h2",{id:"properties"},"Properties"),(0,o.kt)("h3",{id:"gesture"},(0,o.kt)("inlineCode",{parentName:"h3"},"gesture")),(0,o.kt)("p",null,"A gesture object containing the configuration and callbacks. Can be any of the base gestures (",(0,o.kt)("inlineCode",{parentName:"p"},"Tap"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"Pan"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"LongPress"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"Fling"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"Pinch"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"Rotation"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"ForceTouch"),") or any ",(0,o.kt)("a",{parentName:"p",href:"/react-native-gesture-handler/docs/gestures/composed-gestures"},(0,o.kt)("inlineCode",{parentName:"a"},"ComposedGesture"))," (",(0,o.kt)("inlineCode",{parentName:"p"},"Race"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"Simultaneous"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"Exclusive"),")."),(0,o.kt)("admonition",{type:"info"},(0,o.kt)("p",{parentName:"admonition"},"GestureDetector will decide whether to use Reanimated to process provided gestures based on callbacks they have. If any of the callbacks is a worklet, tools provided by the Reanimated will be utilized bringing ability to handle gestures synchronously."),(0,o.kt)("p",{parentName:"admonition"},"Starting with Reanimated 2.3.0 Gesture Handler will provide a ",(0,o.kt)("a",{parentName:"p",href:"/docs/gestures/state-manager"},"StateManager")," in the ",(0,o.kt)("a",{parentName:"p",href:"/docs/gestures/touch-events"},"touch events")," that allows for managing the state of the gesture.")),(0,o.kt)("h3",{id:"userselect-web-only"},(0,o.kt)("inlineCode",{parentName:"h3"},"userSelect")," (",(0,o.kt)("strong",{parentName:"h3"},"web only"),")"),(0,o.kt)("p",null,"This parameter allows to specify which ",(0,o.kt)("inlineCode",{parentName:"p"},"userSelect")," property should be applied to underlying view. Possible values are ",(0,o.kt)("inlineCode",{parentName:"p"},'"none" | "auto" | "text"'),". Default value is set to ",(0,o.kt)("inlineCode",{parentName:"p"},'"none"'),"."),(0,o.kt)("h2",{id:"remarks"},"Remarks"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Gesture Detector will use first native view in its subtree to recognize gestures, however if this view is used only to group its children it may get automatically ",(0,o.kt)("a",{parentName:"li",href:"https://reactnative.dev/docs/view#collapsable-android"},"collapsed"),". Consider this example:",(0,o.kt)(i,{mdxType:"FunctionalComponents"}),"If we were to remove the collapsable prop from the View, the gesture would stop working because it would be attached to a view that is not present in the view hierarchy. Gesture Detector adds this prop automatically to its direct child but it's impossible to do automatically for more complex view trees.")))}m.isMDXComponent=!0}}]);